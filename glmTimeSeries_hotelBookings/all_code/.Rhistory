########
mean(ifelse(df.train$IsCanceled != predicted.glm1.insample, 1, 0))
mean(ifelse(df.train$IsCanceled == predicted.glm1.insample, 1, 0))
#######################
cut_off <- 0.4401000#
#######################
prob.glm1.insample <- predict(df.glm1,type = "response")
predicted.glm1.insample <- (prob.glm1.insample > cut_off)
predicted.glm1.insample <- as.numeric(predicted.glm1.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$IsCanceled, predicted.glm1.insample, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$IsCanceled != predicted.glm1.insample, 1, 0))
mean(ifelse(df.train$IsCanceled == predicted.glm1.insample, 1, 0))
#######################
cut_off <- 0.4401000#
#######################
prob.glm1.insample <- predict(df.glm1,type = "response")
predicted.glm1.insample <- (prob.glm1.insample > cut_off)
predicted.glm1.insample <- as.numeric(predicted.glm1.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$IsCanceled, predicted.glm1.insample, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$IsCanceled != predicted.glm1.insample, 1, 0))
mean(ifelse(df.train$IsCanceled == predicted.glm1.insample, 1, 0))
library('ROCR')
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm1.outsample, df.test$IsCanceled)
#######################
cut_off <- 0.4401000#
#######################
prob.glm1.outsample <- predict(df.glm1, type = "response",newdata = df.test)
predicted.glm1.outsample <- (prob.glm1.outsample > cut_off)
predicted.glm1.outsample <- as.numeric(predicted.glm1.outsample)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, predicted.glm1.outsample, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != predicted.glm1.outsample, 1, 0))
#######################
cut_off <- 0.4401000#
#######################
prob.glm1.outsample <- predict(df.glm1, type = "response",newdata = df.test)
predicted.glm1.outsample <- (prob.glm1.outsample > cut_off)
predicted.glm1.outsample <- as.numeric(predicted.glm1.outsample)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, predicted.glm1.outsample, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != predicted.glm1.outsample, 1, 0))
mean(ifelse(df.train$IsCanceled == predicted.glm1.insample, 1, 0))
#######################
cut_off <- 0.4401000#
#######################
prob.glm1.outsample <- predict(df.glm1, type = "response",newdata = df.test)
predicted.glm1.outsample <- (prob.glm1.outsample > cut_off)
predicted.glm1.outsample <- as.numeric(predicted.glm1.outsample)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, predicted.glm1.outsample, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != predicted.glm1.outsample, 1, 0))
mean(ifelse(df.train$IsCanceled == predicted.glm1.insample, 1, 0))
library('ROCR')
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm1.outsample, df.test$IsCanceled)
perf <- performance(pred, "tpr", "fpr")
rocr.auc.lr = as.numeric(performance(pred, "auc")@y.values)
plot(perf, colorize = TRUE,
main = 'ROC Curve')
mtext(paste('Logistic Regression - auc : ', round(rocr.auc.lr, 5)))
#Get the AUC
unlist(slot(performance(pred, "auc"), "y.values"))
#
####################################################################
# ODDS OF DEFAULT BASED ON WEIGHTS(COEFFICIENTS) GIVEN TO VARIABLES#
####################################################################
# How odds of default change by changing one unit of the variable.
temp_compare <- as.data.frame(exp(cbind(OR = coef(df.glm1))))
temp_compare
library(data.table)
setDT(temp_compare, keep.rownames = TRUE)[]
temp_compare <- temp_compare[order(temp_compare$OR,decreasing = TRUE),]
temp_compare <- temp_compare[!is.infinite(temp_compare$OR)]
temp_compare <- temp_compare[!is.na(temp_compare$OR)]
library(glmnet)
df.Lasso <- glmnet(datos_train_x, as.factor(datos_train_y), alpha = 1.0, family = "binomia")
prob <- predict(df.Lasso, newx = datos_train_x, type = "response")
res <- c()
for (j in 1:ncol(prob)){
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col
result[i,2] <- cost1(df.train$IsCanceled, prob[,j])
}
##plot(result, ylab = "Cost in Training Set")
res <- c(res,as.double(result[which.min(result[,2]),][2]))
}
which(res == min(res))[1]
result = cbind(searchgrid, NA)
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col (which(res == min(res))[1])
result[i,2] <- cost1(df.train$IsCanceled, prob[,98])
}
plot(result, ylab = "Cost in Training Set")
result[which.min(result[,2]),]
# searchgrid
#  0.4301000  0.1511483
library(glmnet)
df.Lasso <- glmnet(datos_train_x, as.factor(datos_train_y), alpha = 1.0, family = "binomia")
prob <- predict(df.Lasso, newx = datos_train_x, type = "response")
res <- c()
for (j in 1:ncol(prob)){
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col
result[i,2] <- cost1(df.train$IsCanceled, prob[,j])
}
##plot(result, ylab = "Cost in Training Set")
res <- c(res,as.double(result[which.min(result[,2]),][2]))
}
which(res == min(res))[1]
result = cbind(searchgrid, NA)
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col (which(res == min(res))[1])
result[i,2] <- cost1(df.train$IsCanceled, prob[,98])
}
plot(result, ylab = "Cost in Training Set")
result[which.min(result[,2]),]
# searchgrid
#  0.4301000  0.1511483
which(res == min(res))[1]
library(glmnet)
df.Lasso <- glmnet(datos_train_x, as.factor(datos_train_y), alpha = 1.0, family = "binomia")
prob <- predict(df.Lasso, newx = datos_train_x, type = "response")
res <- c()
for (j in 1:ncol(prob)){
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col
result[i,2] <- cost1(df.train$IsCanceled, prob[,j])
}
##plot(result, ylab = "Cost in Training Set")
res <- c(res,as.double(result[which.min(result[,2]),][2]))
}
which(res == min(res))[1]
result = cbind(searchgrid, NA)
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col (which(res == min(res))[1])
result[i,2] <- cost1(df.train$IsCanceled, prob[,98])
}
plot(result, ylab = "Cost in Training Set")
result[which.min(result[,2]),]
# searchgrid
#  0.4301000  0.1511483
#######################
cut_off <- 0.4301000#
#######################
prob.Lasso <-  as.double(prob[,98])
prob.Lasso <- (prob.Lasso > cut_off)
prob.Lasso <- as.numeric(prob.Lasso)
###################
# CONFUSION MATRIX#
###################
table(df.train$IsCanceled, prob.Lasso, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$IsCanceled != prob.Lasso, 1, 0))
#######################
cut_off <- 0.4301000#
#######################
prob <- predict(df.Lasso, newx = datos_test_x, type = "response")
prob.Lasso <-  as.double(prob[,98])
prob.Lasso <- (prob.Lasso > cut_off)
prob.Lasso <- as.numeric(prob.Lasso)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, prob.Lasso, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != prob.Lasso, 1, 0))
mean(ifelse(df.train$IsCanceled == prob.Lasso, 1, 0))
#######################
cut_off <- 0.4301000#
#######################
prob <- predict(df.Lasso, newx = datos_test_x, type = "response")
prob.Lasso <-  as.double(prob[,98])
prob.Lasso <- (prob.Lasso > cut_off)
prob.Lasso <- as.numeric(prob.Lasso)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, prob.Lasso, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != prob.Lasso, 1, 0))
mean(ifelse(df.train$IsCanceled == prob.Lasso, 1, 0))
## LOGISTIC REGRESSION
Logistic regression is a method for fitting a regression curve, y = f(x), when y is a categorical variable.
The typical use of this model is predicting y given a set of predictors x. The predictors can be continuous, categorical or a mix of both.
- PREDICTIVE MODEL: Multicolineality is not relevant as we are not searching for an explanatory model.
### TRAIN AND TEST
```{r}
#TRAINING AND TESTING DATA
set.seed(131822)
n <- nrow(raw_data_prediction)
scaleDF  <- scale(raw_data_prediction)
id_train <- sample(1:n , 0.80*n)
df.train <- as.data.frame(scaleDF[id_train,])
df.train$IsCanceled <- raw_data[id_train,]$IsCanceled
df.test  <- as.data.frame(scaleDF[-id_train,])
df.test$IsCanceled <- raw_data[-id_train,]$IsCanceled
```
#### Train Target Variable %
```{r}
target <- as.data.frame(df.train %>% group_by(IsCanceled) %>% summarise(counts = n())) %>% mutate(perc = counts/nrow(df.train))
ggplot(target, aes(x = IsCanceled, y = perc)) + geom_bar(stat = "identity") +
geom_text(aes(label = round(perc,2)))
```
#### Test Target Variable %
```{r}
target <- as.data.frame(df.test %>% group_by(IsCanceled) %>% summarise(counts = n())) %>% mutate(perc = counts/nrow(df.test))
ggplot(target, aes(x = IsCanceled, y = perc)) + geom_bar(stat = "identity") +
geom_text(aes(label = round(perc,2)))
```
### Logistic Regression
```{r}
#######################
# COST IN TRAINING SET#
#######################
searchgrid = seq(0.0001,0.6, 0.01)
result = cbind(searchgrid, NA)
# in the cost function, both r and pi are vectors, r=truth, pi=predicted probability
cost1 <- function(r, pi){
weight1 <- 1
weight0 <- 1
c1 <- (r == 1) & (pi < pcut) # true if actual 1 but predict 0. FP (False Positive)
c0 <- (r == 0) & (pi > pcut) #true if actual 0 but predict 1. FN (False Negative)
return(mean(weight1 * c1 + weight0 * c0))
}
```
#### Train and Test sets for Regularization
```{r}
## Train
datos_train_x <- model.matrix(IsCanceled ~ ., df.train)[, -1]
datos_train_y <- df.train$IsCanceled
## test
datos_test_x <- model.matrix(IsCanceled ~ ., df.test)[, -1]
datos_test_y <- df.test$IsCanceled
```
#### Logistic Regression model
```{r}
df.glm1 <- glm(IsCanceled ~ ., family = binomial, df.train)
prob <- predict(df.glm1,type = "response")
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col
result[i,2] <- cost1(df.train$IsCanceled, prob)
}
plot(result, ylab = "Cost in Training Set")
result[which.min(result[,2]),]
# searchgrid
# 0.4401000  0.1512731
```
### PREDICTION TRAIN
```{r}
#######################
cut_off <- 0.4401000#
#######################
prob.glm1.insample <- predict(df.glm1,type = "response")
predicted.glm1.insample <- (prob.glm1.insample > cut_off)
predicted.glm1.insample <- as.numeric(predicted.glm1.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$IsCanceled, predicted.glm1.insample, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$IsCanceled != predicted.glm1.insample, 1, 0))
mean(ifelse(df.train$IsCanceled == predicted.glm1.insample, 1, 0))
```
### PREDICTION TEST
```{r}
#######################
cut_off <- 0.4401000#
#######################
prob.glm1.outsample <- predict(df.glm1, type = "response",newdata = df.test)
predicted.glm1.outsample <- (prob.glm1.outsample > cut_off)
predicted.glm1.outsample <- as.numeric(predicted.glm1.outsample)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, predicted.glm1.outsample, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != predicted.glm1.outsample, 1, 0))
mean(ifelse(df.train$IsCanceled == predicted.glm1.insample, 1, 0))
```
### ROC CURVE
Our Area Under the Curve is
ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. It quantifies the tradeoff we're making between the TPR (True Positive Rate) and the false positive rate (FPR) at various cutoff settings ( between 0 and 1 ). As TPR increases, FPR increases too, so we want to reach the highest TPR before the FPR increases too much. This means that we want our AUC to be really close to 1.
```{r}
library('ROCR')
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm1.outsample, df.test$IsCanceled)
perf <- performance(pred, "tpr", "fpr")
rocr.auc.lr = as.numeric(performance(pred, "auc")@y.values)
plot(perf, colorize = TRUE,
main = 'ROC Curve')
mtext(paste('Logistic Regression - auc : ', round(rocr.auc.lr, 5)))
```
```{r}
#Get the AUC
unlist(slot(performance(pred, "auc"), "y.values"))
#
```
```{r}
####################################################################
# ODDS OF CANCELED BASED ON WEIGHTS(COEFFICIENTS) GIVEN TO VARIABLES#
####################################################################
# How odds of default change by changing one unit of the variable.
temp_compare <- as.data.frame(exp(cbind(OR = coef(df.glm1))))
temp_compare
library(data.table)
setDT(temp_compare, keep.rownames = TRUE)[]
temp_compare <- temp_compare[order(temp_compare$OR,decreasing = TRUE),]
temp_compare <- temp_compare[!is.infinite(temp_compare$OR)]
temp_compare <- temp_compare[!is.na(temp_compare$OR)]
```
#### Lasso for Feature Selection
```{r}
library(glmnet)
df.Lasso <- glmnet(datos_train_x, as.factor(datos_train_y), alpha = 1.0, family = "binomia")
prob <- predict(df.Lasso, newx = datos_train_x, type = "response")
res <- c()
for (j in 1:ncol(prob)){
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col
result[i,2] <- cost1(df.train$IsCanceled, prob[,j])
}
##plot(result, ylab = "Cost in Training Set")
res <- c(res,as.double(result[which.min(result[,2]),][2]))
}
which(res == min(res))[1]
result = cbind(searchgrid, NA)
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col (which(res == min(res))[1])
result[i,2] <- cost1(df.train$IsCanceled, prob[,98])
}
plot(result, ylab = "Cost in Training Set")
result[which.min(result[,2]),]
# searchgrid
#  0.4301000  0.1511483
```
### PREDICTION TRAIN
```{r}
#######################
cut_off <- 0.4301000#
#######################
prob.Lasso <-  as.double(prob[,98])
prob.Lasso <- (prob.Lasso > cut_off)
prob.Lasso <- as.numeric(prob.Lasso)
###################
# CONFUSION MATRIX#
###################
table(df.train$IsCanceled, prob.Lasso, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$IsCanceled != prob.Lasso, 1, 0))
```
### PREDICTION TEST
```{r}
#######################
cut_off <- 0.4301000#
#######################
prob <- predict(df.Lasso, newx = datos_test_x, type = "response")
prob.Lasso <-  as.double(prob[,98])
prob.Lasso <- (prob.Lasso > cut_off)
prob.Lasso <- as.numeric(prob.Lasso)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, prob.Lasso, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != prob.Lasso, 1, 0))
mean(ifelse(df.train$IsCanceled == prob.Lasso, 1, 0))
```
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.Lasso, df.test$IsCanceled)
perf <- performance(pred, "tpr", "fpr")
rocr.auc.lr = as.numeric(performance(pred, "auc")@y.values)
plot(perf, colorize = TRUE,
main = 'ROC Curve')
#######################
cut_off <- 0.4301000#
#######################
prob <- predict(df.Lasso, newx = datos_test_x, type = "response")
prob.Lasso <-  as.double(prob[,98])
prob.Lasso <- (prob.Lasso > cut_off)
prob.Lasso <- as.numeric(prob.Lasso)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, prob.Lasso, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != prob.Lasso, 1, 0))
mean(ifelse(df.train$IsCanceled == prob.Lasso, 1, 0))
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.Lasso, df.test$IsCanceled)
perf <- performance(pred, "tpr", "fpr")
rocr.auc.lr = as.numeric(performance(pred, "auc")@y.values)
plot(perf, colorize = TRUE,
main = 'ROC Curve')
mtext(paste('Logistic Regression - auc : ', round(rocr.auc.lr, 5)))
#Get the AUC
unlist(slot(performance(pred, "auc"), "y.values"))
#
library(glmnet)
df.Lasso <- glmnet(datos_train_x, as.factor(datos_train_y), alpha = 1.0, family = "binomial")
prob <- predict(df.Lasso, newx = datos_train_x, type = "response")
res <- c()
for (j in 1:ncol(prob)){
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col
result[i,2] <- cost1(df.train$IsCanceled, prob[,j])
}
##plot(result, ylab = "Cost in Training Set")
res <- c(res,as.double(result[which.min(result[,2]),][2]))
}
which(res == min(res))[1]
result = cbind(searchgrid, NA)
for (i in 1:length(searchgrid))
{
pcut <- result[i,1]
#assign the cost to the 2nd col (which(res == min(res))[1])
result[i,2] <- cost1(df.train$IsCanceled, prob[,98])
}
plot(result, ylab = "Cost in Training Set")
result[which.min(result[,2]),]
# searchgrid
#  0.4301000  0.1511483
#######################
cut_off <- 0.4301000#
#######################
prob <- predict(df.Lasso, newx = datos_test_x, type = "response")
prob.Lasso <-  as.double(prob[,98])
prob.Lasso <- (prob.Lasso > cut_off)
prob.Lasso <- as.numeric(prob.Lasso)
###################
# CONFUSION MATRIX#
###################
table(df.test$IsCanceled, prob.Lasso, dnn = c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.test$IsCanceled != prob.Lasso, 1, 0))
mean(ifelse(df.train$IsCanceled == prob.Lasso, 1, 0))
df.Lasso
